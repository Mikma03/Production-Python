{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in the lecture what an LRU cache is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Python provides us a decorator to apply an LRU caching mechanism to a function (called **memoization**), we are going to try doing it ourselves first as another excellent example of decorators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to worry about cache size - for simplicity we'll allow our cache to always grow unbounded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simplification we are going to make is that we are not going to handle caching functions that use keyword-only arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's LRU cache mechanism does not have these two simplifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(func):\n",
    "    def inner(*args):\n",
    "        result = func(*args)\n",
    "        return result\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our standard pattern for creating a decorator (albeit only considering positional arguments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a cache where we can store/recall the result of calling `func(*args)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we'll want to do is create a dictionary - but we don't want to create the dictionary inside `inner`, because that means every time we call `inner` (the decorated function), we would start with an empty cache dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we're going to define the cache in the outer `cache` function, and access it as a free variable in `inner`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `cache` gets created every time `cache` is called, but the returned `inner` function can use that same `cache` over and over again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So next, we need to calculate a key to represent all the arguments that were passed to `inner` (that eventually calls `func`) - and that's simply the tuple `args`. \n",
    "\n",
    "Now, it does mean that the tuple `args` must be hashable - just like Python's own implementation of LRU cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(func):\n",
    "    print('initialize cache')\n",
    "    cache = {}\n",
    "    def inner(*args):\n",
    "        key = args\n",
    "        if key in cache:\n",
    "            print('Cache hit')\n",
    "            return cache[args]\n",
    "        else:\n",
    "            result = func(*args)\n",
    "            cache[args] = result\n",
    "            return result\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can start using it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize cache\n"
     ]
    }
   ],
   "source": [
    "@cache\n",
    "def my_func(a, b):\n",
    "    print(f'evaluating my_func({a}, {b})...')\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating my_func(1, 2)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the original `my_func` was called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we use the same parameters a second time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get the result back without the function actually executing - the result was obtained from cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can decorate another function with the same decorator, and it will have it's own cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize cache\n"
     ]
    }
   ],
   "source": [
    "@cache\n",
    "def add(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the basic idea behind the `lru_cache` decorator.\n",
    "\n",
    "Let's use that one instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=2)\n",
    "def add(a, b):\n",
    "    print(f'Calling add({a}, {b})...')\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add(1, 1)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add(2, 2)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we made the cache size `2`, which means if we now call with a new set of args:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add(3, 3)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only was the function evaluated (these args were not in the cache), but it also cleared out the oldest entry in the cache - (1, 1). (2, 2) is still there though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add(1, 1)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a function that takes a long time to run, and you often call it with the same arguments, don't forget an LRU cache - it can greatly speed up your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a very simple example to calculate the Fibonacci numbers:\n",
    "\n",
    "```\n",
    "0, 1, 1, 2, 3, 5, 8, 13, 21, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sequence starts with `0` and `1`, and every element thereafter is the sum of the previous two - so there is a recursive relationship, and we could define a mamethematical function to produce the `n`th number (assuming we are indexing starting at `0`), this way:\n",
    "\n",
    "```\n",
    "Fib(0) = 0\n",
    "Fib(1) = 1\n",
    "Fib(n) = Fib(n-1) + Fib(n-2), n > 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express this same recursive definition using a Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function may seem odd as it is calling itself - this is known as a recursive function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way it works is that if we call `fib(0)` or `fib(1)` it just returns `0` and `1` respectively.\n",
    "\n",
    "If we call `fib(2)` it will call `fib(0)` and `fib(1)` which return  `0` and `1`.\n",
    "\n",
    "If we call `fib(3)` it will call `fib(1)` and `fib(2)` - `fib(1)` will just return `1`, but `fib(2)` calls `fib(0)` and `fib(1)`.\n",
    "\n",
    "If we call `fib(4)` it will call `fib(2)` and `fib(3)`, and the processing path for those two calls will follow what we just saw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So recursion is a very simple approach to implement certain algorithms (like Fibonacci, factorials, etc).\n",
    "\n",
    "But they can often become computationally intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put a print statement to indicate when the `fib` function gets called, and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    print(f'fib({n}) called...')\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(0) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(1) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(4) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(5) called...\n",
      "fib(4) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the higher we go the more function calls are made - in fact the number of calls grows so fast that the timing to calulate the `n`th Fibonacci number even for relatively small `n` is prohibitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove that `print` statement first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(30)=832040, elapsed: 0.27679114000000005\n",
      "fib(31)=1346269, elapsed: 0.41020096800000005\n",
      "fib(32)=2178309, elapsed: 0.6584909400000001\n",
      "fib(33)=3524578, elapsed: 1.1819654540000002\n",
      "fib(34)=5702887, elapsed: 1.7600036860000001\n",
      "fib(35)=9227465, elapsed: 2.8420717659999992\n",
      "fib(36)=14930352, elapsed: 4.518468769999999\n",
      "fib(37)=24157817, elapsed: 7.279664487999998\n"
     ]
    }
   ],
   "source": [
    "for n in range(30, 38):\n",
    "    start = perf_counter()\n",
    "    result = fib(n)\n",
    "    end = perf_counter()\n",
    "    print(f'fib({n})={result}, elapsed: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of course is that when we call `fib(37)` it calls `fib(35)` and `fib(36)`.\n",
    "In turn `fib(35)` calls `fib(34) and fib(33)` and `fib(36)` calls `fib(34)` and `fib(35)`, etc - so we end up calling the same `fib(n)` over and over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we could cache the results of calling `fib(n)` - then we could use the cache for a previous Fibonacci number without recalculating it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's precisely what the LRU cache can do for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put that `print` statement back and see the call stack when we call `fib(6)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    print(f'fib({n}) called...')\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(6) called...\n",
      "fib(5) called...\n",
      "fib(4) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n",
      "fib(4) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n",
      "fib(1) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply that LRU cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def fib(n):\n",
    "    print(f'fib({n}) called...')\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(6) called...\n",
      "fib(5) called...\n",
      "fib(4) called...\n",
      "fib(3) called...\n",
      "fib(2) called...\n",
      "fib(1) called...\n",
      "fib(0) called...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the number of function calls greatly decreased, and we can redo our timings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(30)=832040, elapsed: 1.913599999880944e-05\n",
      "fib(31)=1346269, elapsed: 1.1970000031169548e-06\n",
      "fib(32)=2178309, elapsed: 7.240000030606097e-07\n",
      "fib(33)=3524578, elapsed: 6.570000010697186e-07\n",
      "fib(34)=5702887, elapsed: 6.900000002474371e-07\n",
      "fib(35)=9227465, elapsed: 6.040000002371926e-07\n",
      "fib(36)=14930352, elapsed: 6.429999999113534e-07\n",
      "fib(37)=24157817, elapsed: 5.9699999965801e-07\n"
     ]
    }
   ],
   "source": [
    "@lru_cache\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "for n in range(30, 38):\n",
    "    start = perf_counter()\n",
    "    result = fib(n)\n",
    "    end = perf_counter()\n",
    "    print(f'fib({n})={result}, elapsed: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much faster, and even for larger `n`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(100)=354224848179261915075, elapsed: 3.7771999998881256e-05\n",
      "fib(101)=573147844013817084101, elapsed: 9.4600000011269e-07\n",
      "fib(102)=927372692193078999176, elapsed: 7.40000000831742e-07\n",
      "fib(103)=1500520536206896083277, elapsed: 9.709999986284856e-07\n",
      "fib(104)=2427893228399975082453, elapsed: 7.569999986856146e-07\n",
      "fib(105)=3928413764606871165730, elapsed: 6.95000000661139e-07\n",
      "fib(106)=6356306993006846248183, elapsed: 6.570000010697186e-07\n",
      "fib(107)=10284720757613717413913, elapsed: 6.480000003250552e-07\n",
      "fib(108)=16641027750620563662096, elapsed: 6.639999980961875e-07\n",
      "fib(109)=26925748508234281076009, elapsed: 6.95000000661139e-07\n"
     ]
    }
   ],
   "source": [
    "for n in range(100, 110):\n",
    "    start = perf_counter()\n",
    "    result = fib(n)\n",
    "    end = perf_counter()\n",
    "    print(f'fib({n})={result}, elapsed: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we really only need to cache the results of the last three Fibonacci numbers to gain efficiencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(30)=832040, elapsed: 1.1567000001377892e-05\n",
      "fib(31)=1346269, elapsed: 1.89200000022538e-06\n",
      "fib(32)=2178309, elapsed: 1.069999999714355e-06\n",
      "fib(33)=3524578, elapsed: 7.12999998597752e-07\n",
      "fib(34)=5702887, elapsed: 7.310000000870787e-07\n",
      "fib(35)=9227465, elapsed: 7.350000004180401e-07\n",
      "fib(36)=14930352, elapsed: 1.018000002517283e-06\n",
      "fib(37)=24157817, elapsed: 9.580000011055745e-07\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=3)\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "for n in range(30, 38):\n",
    "    start = perf_counter()\n",
    "    result = fib(n)\n",
    "    end = perf_counter()\n",
    "    print(f'fib({n})={result}, elapsed: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiencies are not as great as an unbounded cache, but the efficiency gain is noetheless perfectly acceptable in view of the fact that we are not growing our cache unbounded as we calculate larger and larger Fibonacci numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `timeit` to see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=3)\n",
    "def fib_3(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_3(n-1) + fib_3(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def fib_unbounded(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_unbounded(n-1) + fib_unbounded(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.678542482000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit(\n",
    "    '[fib_3(n) for n in range(100, 200)]', \n",
    "    globals=globals(), \n",
    "    number=10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07769970500000056"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit(\n",
    "    '[fib_unbounded(n) for n in range(100, 200)]', \n",
    "    globals=globals(), \n",
    "    number=10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as is often the case, we need to balance performance against memory usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
